{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "*Part of the course:\n",
    "Machine Learning (code: INFOB3ML), fall 2025, Utrecht University*\n",
    "\n",
    "Total points: 10 + 1 bonus\n",
    "\n",
    "Deadline: Friday 3 October, 23:59 *(This is the Friday after the exam. It is recommended to complete (most of) the assignment before the exam, as it is intended to help you understand the material.)*\n",
    "\n",
    "**Write your names and student numbers here: ___**\n",
    "\n",
    "* Code is graded based on whether it runs correctly, but also based on code quality. Write legible code, use sensible variable names, and make sure your code is properly commented.\n",
    "* Submit your code in Brightspace following the instructions given there.\n",
    "\n",
    "**Before you submit, click Kernel > Restart Kernel and Run All Cells to make sure you submit a working version of your code!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coin Flipping\n",
    "In this second assignment, you're going to see how some of the central concepts from Bayesian machine learning behave in different scenarios. You'll be looking at the coin flipping example that has also taken a central place in the book and the lectures so far.\n",
    "\n",
    "When flipping a coin $N$ times, under very reasonable assumptions, the probability of getting $y$ times heads is given by the binomial distribution with parameters $N$ and $r$, where $r$ is the probability that the coin lands heads on one flip.\n",
    "\n",
    "SciPy includes functions for working with many well-known distributions, allowing you to sample from them and compute probabilities and densities, as well as many other properties. For the binomial distribution, you can compute the probability of getting $y$ heads with `binom.pmf(y, N, r)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1** (1 point): For the values $r = 0.00, 0.01, \\ldots, 1.00$, compute the likelihood of seeing 9 out of 10 heads, and plot these in a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import binom, beta\n",
    "import scipy.special as sps\n",
    "\n",
    "# Use np.linspace to get a NumPy array of evenly spaced values for r\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictors\n",
    "\n",
    "We will define three different \"predictor\" classes. The first will use maximum likelihood to make its predictions, the other two will use a Bayesian approach, with different kinds of priors. Each predictor object will have the following methods (also known as member functions):\n",
    "\n",
    "* `predictor.updated(num_heads, N)` returns a new predictor object. This predictor object copies the information from the original predictor object `predictor`, but updated with the information that `N` additional new data points have been seen, `num_heads` of which were heads.\n",
    "\n",
    "* `predictor.predict()` returns a number between 0 and 1, which is the probability that this predictor assigns to the next coin flip coming up heads.\n",
    "\n",
    "* `predictor.marginal_likelihood(num_heads, N)` returns the Bayesian marginal likelihood. This is only defined for Bayesian predictors; for other types, it returns `np.nan` (\"not a number\").\n",
    "\n",
    "The definition of the `MaximumLikelihoodPredictor` predictor class is given below (you don't need to change it), with some testing code to see it in action. It computes the maximum likelihood estimator for the probability that the coin lands heads, and uses this value as its prediction of how likely the next coin is to land heads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: MaximumLikelihoodPredictor with num_heads = 0, N = 0\n",
      "After: MaximumLikelihoodPredictor with num_heads = 2, N = 2\n",
      "prediction = 1.0\n"
     ]
    }
   ],
   "source": [
    "class MaximumLikelihoodPredictor:\n",
    "    def __init__(self):\n",
    "        self.num_heads = 0\n",
    "        self.N = 0\n",
    "    def __str__(self):\n",
    "        return f\"MaximumLikelihoodPredictor with num_heads = {self.num_heads}, N = {self.N}\"\n",
    "    def updated(self, num_heads, N):\n",
    "        after = MaximumLikelihoodPredictor()\n",
    "        after.num_heads = self.num_heads + num_heads\n",
    "        after.N = self.N + N\n",
    "        return after\n",
    "    def predict(self):\n",
    "        return self.num_heads / self.N\n",
    "    def get_marginal_likelihood(self, num_heads, N):\n",
    "        return np.nan\n",
    "    def plot(self):\n",
    "        pass\n",
    "\n",
    "# ██████████ TEST ██████████\n",
    "predictor = MaximumLikelihoodPredictor()\n",
    "print(\"Before:\", predictor)\n",
    "# After two flips, both heads, you should get:\n",
    "# After: MaximumLikelihoodPredictor with num_heads = 2, N = 2\n",
    "# which should predict that the next flip will land heads with probability 1.0\n",
    "predictor_after = predictor.updated(2, 2)\n",
    "print(\"After:\", predictor_after)\n",
    "print(\"prediction =\", predictor_after.predict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two Bayesian predictor classes will be defined next. The first will use a discrete prior: instead of considering the entire range from 0 to 1 (containing infinitely many numbers) as possible values for $R$, it will only consider some finite set of such numbers. It assigns some probability to each of them, and these probabilities add up to 1. This finite set and the associated probabilities can be represented in Python by a dictionary, that maps a value $r$ to the probability assigned to it by the prior. For example, `prior.probability_for_r[.5] = .2` means that $P(R = .5) = .2$.\n",
    "\n",
    "Being a Bayesian predictor, the `updated` function will use Bayes' theorem to compute the posterior distribution after having seen the data. For a discrete prior, the posterior will assign probability to the same set of values of $r$, but the probabilities assigned will usually be different.\n",
    "\n",
    "**Task 2** (1 point): Complete the implementation of the `updated` function below. (You'll finish the other incomplete functions in later tasks.) You can use the provided testing code to see if the posterior looks as it should."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior: DiscretePriorPredictor with P(R = 0.3333) = 0.5000; P(R = 0.6667) = 0.5000\n",
      "Posterior: DiscretePriorPredictor with P(R = 0.3333) = 0.5000; P(R = 0.6667) = 0.5000\n",
      "prediction = 0.5\n",
      "marginal likelihood = 1\n"
     ]
    }
   ],
   "source": [
    "class DiscretePriorPredictor:\n",
    "    def __init__(self):\n",
    "        self.probability_for_r = {}\n",
    "    def __str__(self):\n",
    "        return (\"DiscretePriorPredictor with \"\n",
    "                + \"; \".join([f\"P(R = {r:.4f}) = {prior_prob:.4f}\"\n",
    "                             for r, prior_prob in self.probability_for_r.items()]))\n",
    "    def updated(self, num_heads, N):\n",
    "        if not len(self.probability_for_r):\n",
    "            raise ValueError(\"assign probabilities for DiscretePriorPredictor before calling updated\")\n",
    "        posterior = DiscretePriorPredictor()\n",
    "        total_prob = 0.0\n",
    "        for r, prior_prob in self.probability_for_r.items():\n",
    "            # Compute the value in the numerator of Bayes' theorem, and\n",
    "            # assign it to posterior.probability_for_r[r]\n",
    "                        \n",
    "            # YOUR CODE HERE FOR TASK 2\n",
    "            numerator = 1 # CHANGE THIS\n",
    "\n",
    "            posterior.probability_for_r[r] = numerator\n",
    "            total_prob += numerator\n",
    "        # Finaly, divide everything by the sum. The sum is cast to a numpy float\n",
    "        # to turn division-by-zero errors into warnings.\n",
    "        for r, posterior_prob in posterior.probability_for_r.items():\n",
    "            posterior.probability_for_r[r] /= np.float64(total_prob)\n",
    "        return posterior\n",
    "    def predict(self):\n",
    "        if not len(self.probability_for_r):\n",
    "            raise ValueError(\"assign probabilities for DiscretePriorPredictor before calling predict\")\n",
    "            \n",
    "        # YOUR CODE HERE FOR TASK 3\n",
    "        \n",
    "        return .5 # CHANGE THIS\n",
    "    def get_marginal_likelihood(self, num_heads, N):\n",
    "        if not len(self.probability_for_r):\n",
    "            raise ValueError(\"assign probabilities for DiscretePriorPredictor before calling get_marginal_likelihood\")\n",
    "            \n",
    "        # YOUR CODE HERE FOR TASK 4\n",
    "\n",
    "        return 1 # CHANGE THIS\n",
    "    def plot(self):\n",
    "        # YOUR CODE HERE FOR TASK 5\n",
    "        pass\n",
    "\n",
    "# ██████████ TEST ██████████\n",
    "discrete_prior = DiscretePriorPredictor()\n",
    "discrete_prior.probability_for_r[1/3] = 1/2\n",
    "discrete_prior.probability_for_r[2/3] = 1/2\n",
    "print(\"Prior:\", discrete_prior)\n",
    "# After two flips, both heads, you should get:\n",
    "# Posterior: DiscretePrior with P(R = 0.3333) = 0.2000; P(R = 0.6667) = 0.8000,\n",
    "# which should predict that the next flip will land heads with probability 0.6.\n",
    "# The marginal likelihood for these data and prior should be ~ 0.2777.\n",
    "discrete_posterior = discrete_prior.updated(2, 2)\n",
    "print(\"Posterior:\", discrete_posterior)\n",
    "print(\"prediction =\", discrete_posterior.predict())\n",
    "print(\"marginal likelihood =\", discrete_prior.get_marginal_likelihood(2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Bayesian predictive distribution is the distribution over the outcome of a new coin flip, conditioned on the data. Calling the `predict` function on the posterior should output the probability $P(\\text{new flip = heads} | \\text{previous data})$. You saw how to compute it on the slides of lecture 5.\n",
    "\n",
    "**Task 3** (1 point): Implement the `predict` function above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the marginal likelihood is the quantity that occurs in the denominator of Bayes' theorem. In this case, the prior is discrete, so the marginal likelihood is given by a sum.\n",
    "\n",
    "The marginal likelihood is *not conditioned on the data*. In our code, the `posterior` object (computed by `updated`) can tell us things that involve conditioning on the data. But for the marginal likelihood, we'll need to original `prior` object. You'll see that the testing code calls `prior.get_marginal_likelihood`, not `posterior.get_marginal_likelihood`.\n",
    "\n",
    "**Task 4** (0.5 points): Implement the `get_marginal_likelihood` function above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 5** (1 point): Implement the `plot` function above that visualises a `DiscretePriorPredictor` using vertical lines whose height denotes the probability attached to some value of $r$: something like [this figure from Wikipedia](https://en.wikipedia.org/wiki/Discrete_uniform_distribution#/media/File:Uniform_discrete_pmf_svg.svg). Use `plt.vlines`. Set the horizontal axis to run from -0.05 to 1.05. The code below calls your function to plot the prior and the posterior from the test code above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_prior.plot()\n",
    "discrete_posterior.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final predictor class will use the Beta distribution. This is a continuous prior that considers all values of $r$ between 0 and 1. Being the conjugate prior for the binomial likelihood gives it some major computational advantages.\n",
    "\n",
    "**Task 6** (1 point): Implement `updated` and `predict` below for the `BetaPriorPredictor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior: BetaPriorPredictor with alpha = 1.0000, beta = 1.0000\n",
      "Posterior: BetaPriorPredictor with alpha = 1.0000, beta = 1.0000\n",
      "prediction = 0.5\n",
      "marginal likelihood = 0.3333333333333331\n"
     ]
    }
   ],
   "source": [
    "class BetaPriorPredictor:\n",
    "    def __init__(self, alpha, beta):\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "    def __str__(self):\n",
    "        return f\"BetaPriorPredictor with alpha = {self.alpha:.4f}, beta = {self.beta:.4f}\"\n",
    "    def updated(self, num_heads, N):\n",
    "        # YOUR CODE HERE FOR TASK 6 part 1\n",
    "        \n",
    "        return self # CHANGE THIS\n",
    "    def predict(self):\n",
    "        # YOUR CODE HERE FOR TASK 6 part 2\n",
    "        \n",
    "        return .5 # CHANGE THIS\n",
    "    def get_marginal_likelihood(self, num_heads, N):\n",
    "        if self.alpha < 1e-9 or self.beta < 1e-9:\n",
    "            return np.nan\n",
    "        # The Gamma function may output really large numbers. To avoid\n",
    "        # numerical inaccuracy, the following code works with logarithms instead,\n",
    "        # converting back to the actual number when all Gamma's have been combined.\n",
    "        return (sps.binom(N, num_heads)\n",
    "                * math.exp(math.lgamma(self.alpha + self.beta)\n",
    "                           - math.lgamma(self.alpha)\n",
    "                           - math.lgamma(self.beta)\n",
    "                           + math.lgamma(self.alpha + num_heads)\n",
    "                           + math.lgamma(self.beta + N - num_heads)\n",
    "                           - math.lgamma(self.alpha + self.beta + N)\n",
    "                          )\n",
    "               )\n",
    "    def plot(self):\n",
    "        # YOUR CODE HERE FOR TASK 7\n",
    "        pass\n",
    "\n",
    "# ██████████ TEST ██████████\n",
    "beta_prior = BetaPriorPredictor(1, 1)\n",
    "print(\"Prior:\", beta_prior)\n",
    "# After two flips, both heads, you should get:\n",
    "# Posterior: BetaPrior with alpha = 3.0000, beta = 1.0000\n",
    "# which should predict that the next flip will land heads with probability 0.75\n",
    "# The marginal likelihood for these data and prior should be ~ 0.3333.\n",
    "beta_posterior = beta_prior.updated(2, 2)\n",
    "print(\"Posterior:\", beta_posterior)\n",
    "print(\"prediction =\", beta_posterior.predict())\n",
    "print(\"marginal likelihood =\", beta_prior.get_marginal_likelihood(2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 7** (0.5 points): Implement the `plot` function that visualises a `BetaPriorPredictor` by plotting its probability density function. You can use the `beta` object from `scipy.stats`, which has already been imported. The code below will plot the prior and the posterior from the test code above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_prior.plot()\n",
    "beta_posterior.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 8** (0.5 points): For what values of alpha and beta does the Beta distribution have the same shape as the likelihood you plotted in task 1? Explain your answer, and verify it by showing the plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*YOUR ANSWER HERE*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting with different predictors\n",
    "\n",
    "Next, we want to see the predictors in action. First, the code below creates a list of ten predictors, using the three classes defined above. We'll investigate their behaviour on several different values of the true probability of getting heads. These probabilities are defined below by `true_rs = [0, .3, .5, 2/3, .75, .999]`.\n",
    "\n",
    "Note that the final predictor in the list, `BetaPriorPredictor(0, 0)`, doesn't satisfy the constraints for being a proper Beta prior: that requires $\\alpha > 0$ and $\\beta > 0$. The problem is in the normalisation constant, which is undefined in this case. As we've seen, we can often get away with ignoring the normalisation constant, and by carrying this a bit further, we can use this unnormalised distribution as a prior in Bayes' theorem. Such a thing is called a *degenerate prior*. Often (but not always), the posterior we find will be a proper distribution again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of predictors to be compared.\n",
    "\n",
    "predictors = [MaximumLikelihoodPredictor()]\n",
    "\n",
    "prior = DiscretePriorPredictor()\n",
    "prior.probability_for_r[1/3] = 1/2\n",
    "prior.probability_for_r[2/3] = 1/2\n",
    "predictors.append(prior)\n",
    "\n",
    "prior = DiscretePriorPredictor()\n",
    "prior.probability_for_r[1/3] = 1/3\n",
    "prior.probability_for_r[1/2] = 1/3\n",
    "prior.probability_for_r[2/3] = 1/3\n",
    "predictors.append(prior)\n",
    "\n",
    "prior = DiscretePriorPredictor()\n",
    "prior.probability_for_r[0] = 1/2\n",
    "prior.probability_for_r[1] = 1/2\n",
    "predictors.append(prior)\n",
    "\n",
    "prior = DiscretePriorPredictor()\n",
    "for r in np.linspace(0, 1, 11):\n",
    "    prior.probability_for_r[r] = 1/11\n",
    "predictors.append(prior)\n",
    "\n",
    "prior = DiscretePriorPredictor()\n",
    "for r in np.linspace(0, 1, 101):\n",
    "    prior.probability_for_r[r] = 1/101\n",
    "predictors.append(prior)\n",
    "\n",
    "prior = BetaPriorPredictor(1, 1)\n",
    "predictors.append(prior)\n",
    "\n",
    "prior = BetaPriorPredictor(3, 3)\n",
    "predictors.append(prior)\n",
    "\n",
    "prior = BetaPriorPredictor(.5, .5)\n",
    "predictors.append(prior)\n",
    "\n",
    "prior = BetaPriorPredictor(0, 0)\n",
    "predictors.append(prior)\n",
    "\n",
    "true_rs = [0, .3, .5, 2/3, .75, .999]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each combination of a predictor and a value $r_\\text{true}$ from `true_rs`, we will do the following experiment. We'll sample some training data (100 coin flips) and compute an updated predictor using these data. For the Bayesian predictors, this comes down to computing the posterior distribution. Then we'll sample some test data (again 100 points). For both the training and the test data, the true probability of getting heads on each flip is given by $r_\\text{true}$.\n",
    "\n",
    "Now we want to evaluate how well the predictor does at predicting the test data. There are several ways to measure this. We'll try two different ones: the *logarithmic loss* and the *logarithmic regret*.\n",
    "\n",
    "The **logarithmic loss** is something you may have seen before in other places. For instance, logistic regression is training to minimise this loss, and it's also one of the most popular choices when training neural networks for binary classification problems (there you may have seen it under the name \"cross entropy\"). Suppose the predictor assigns probability $\\hat{r}$ to the outcome heads for a new coin flip $Y_\\text{new}$, and that a new flip actually comes out as $y_\\text{new}$ (1 for heads, 0 for tails). Then the logarithmic loss of this prediction is\n",
    "$$-\\log P_{\\hat{r}} ( Y_\\text{new} = y_\\text{new} ).$$\n",
    "In other words, if the coin in the test data came up heads, the loss is $-\\log (\\hat{r})$; if it came up tails, the loss is $-\\log (1 - \\hat{r})$.\n",
    "\n",
    "The logarithm of 1 is 0, and as $x$ goes down to $0$, $\\log(x)$ goes down to $-\\infty$. So we see that the logarithmic loss is a small positive number if the outcome of the test data point was something the predictor thought was probably going to happen. But if something happens that the predictor thought would happen only with a small probability, the logarithmic loss will be larger.\n",
    "\n",
    "The test set consists of 100 coin flips, and the loss on the test data is the *sum* of the losses of all these coin flips.\n",
    "\n",
    "*Implementation note 1*: the logarithm of 0 is minus infinity, so that $0 \\log(0)$ is undefined. To avoid unnecessary undefined outcomes, write your code in such a way that if no flip happened in the test data for which the predicted probability was 0, then $\\log(0)$ isn't called.\n",
    "\n",
    "*Implementation note 2*: to compute logarithms, use `np.log` (not `math.log`). The advantage of `np.log` here is that if it does encounter a $\\log(0)$, it gives a warning and allows the rest of the experiment to continue, while `math.log` would give an error and stop your code from running further.\n",
    "\n",
    "One issue with logarithmic loss (or any loss, for that matter) is, that it's easier for predictors to get low average losses if $r_\\text{true}$ is close to 0 or 1, but much harder if it's closer to 0.5. To make the comparisons between experiments more fair, we can look at the **regret** corresponding to the loss, so logarithmic regret in our case. The regret equals the loss of a predictor *minus* the loss of an ideal predictor that already knew the value $r_\\text{true}$. In other words, the ideal predictor uses $r_\\text{true}$ in the place where other predictors use $\\hat{r}$. By comparing our predictor's loss to the loss even a clairvoyant predictor would obtain, we'll get numbers that are more meaningful when different values of $r_\\text{true}$ are involved.\n",
    "\n",
    "Like with the losses, the regret on the test data is the *sum* of the regrets of the individual coin flips.\n",
    "\n",
    "**Task 9** (1.5 points): For each combination of predictor and $r_\\text{true}$, repeat this process 100 times (including getting new training and new test data every time), and store the following in three NumPy arrays:\n",
    "\n",
    "* The average loss;\n",
    "\n",
    "* The average regret;\n",
    "\n",
    "* The average marginal likelihood of the *training data* (don't use the test data for this one!)\n",
    "\n",
    "(All averages are over the 100 repeats of the same experiment.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pred = len(predictors)\n",
    "num_rs = len(true_rs)\n",
    "num_repeats = 100\n",
    "N_train = 100\n",
    "N_test = 100\n",
    "average_losses = np.zeros((num_pred, num_rs))\n",
    "average_regrets = np.zeros((num_pred, num_rs))\n",
    "average_marginal_likelihoods = np.zeros((num_pred, num_rs))\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 10** (2 points + 1 bonus point): Now write a short report analysing the results of your experiment. Answer at least the following questions:\n",
    "\n",
    "* For each combination of predictor and $r_\\text{true}$ that gives `inf` or `nan` loss, explain why the average loss isn't finite.\n",
    "\n",
    "* What are the strengths and weaknesses of the ten predictors? In a situation where you don't know anything about $r_\\text{true}$ beforehand, which predictors would you recommend, and which not?\n",
    "\n",
    "* BONUS: Look at the marginal likelihoods, say something about model selection\n",
    "\n",
    "You can accompany your answer by additional code that produces tables or figures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*YOUR ANSWER HERE*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "---\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remember: Before you submit, click Kernel > Restart Kernel and Run All Cells to make sure you submit a working version of your code!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
