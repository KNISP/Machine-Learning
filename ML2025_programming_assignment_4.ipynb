{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Assignment 4: Explainability\n",
    "\n",
    "*Part of the course:\n",
    "Machine Learning (code: INFOB3ML), Fall 2025, Utrecht University*\n",
    "\n",
    "Total points: 10 (100%)\n",
    "\n",
    "Deadline: Friday 31 October, 23:59\n",
    "\n",
    "The stundets should submit one ipynb file per pair.\n",
    "\n",
    "**Write your names and student numbers here:**\n",
    "- Luc Hampsink - 8980713\n",
    "- Mia Loozekoot - 5022681\n",
    "\n",
    "\n",
    "\n",
    "Submit one ipynb file per pair.\n",
    "\n",
    "**Before you submit, click Kernel > Restart & Run All to make sure you submit a working version of your code!**\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Installation\n",
    "\n",
    "For this assignment, we are going to use the following Python packages:\n",
    "\n",
    "matplotlib, pandas, statsmodels, interpret, scikit-learn, openpyxl and graphviz"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Installing packages\n",
    "%pip install graphviz plotnine seaborn\n",
    "%pip install matplotlib pandas numpy statsmodels scikit-learn openpyxl\n",
    "%pip install interpret\n",
    "%pip install scikit-learn --upgrade"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Downloading the data\n",
    "We are going to use the combined cycle power plant dataset. This dataset contains 9568 data points collected from a Combined Cycle Power Plant over 6 years (2006-2011), when the power plant was set to work with full load. We have the following features: hourly average ambient variables Temperature (T), Ambient Pressure (AP), Relative Humidity (RH) and Exhaust Vacuum (V). We will train ML models to predict the net hourly electrical energy output (EP) of the plant.\n",
    "\n",
    "For a detailed description, see: [[Description](https://archive.ics.uci.edu/dataset/294/combined+cycle+power+plant)]\n",
    "\n",
    "We first need to download and prepare data.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Download and unzip data\n",
    "\n",
    "# Windows users: download the data from https://archive.ics.uci.edu/ml/machine-learning-databases/00294/CCPP.zip\n",
    "# and unzip the file manually in the same folder as the python notebook\n",
    "\n",
    "# Note: this cell works fine on Linux based systems and Google Colab\n",
    "# If you run it on a Windows machine, you will get an error (...'wget' is not recognized as an internal or external command...)\n",
    "!wget -c https://archive.ics.uci.edu/ml/machine-learning-databases/00294/CCPP.zip\n",
    "!unzip CCPP.zip"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Loading and preprocessing the data\n",
    "We split the data into training (first 5000 instances) and validation (the subsequent 2000) and test (the last 2568) sets. We will use the training set to train a model, and validation set to optimize the model hyper-parameters.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load and prepare data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# global variables\n",
    "DATA_FILENAME = 'CCPP/Folds5x2_pp.xlsx'\n",
    "FEATURE_NAMES = ['AT', 'V', 'AP', 'RH']\n",
    "LABEL_NAME = 'PE'\n",
    "\n",
    "# Load the data from the excel file\n",
    "def load_data():\n",
    "    def split_feature_label(data_set):\n",
    "        features = data_set[FEATURE_NAMES]\n",
    "        labels = data_set[LABEL_NAME]\n",
    "        return features, labels\n",
    "\n",
    "    data = pd.read_excel(DATA_FILENAME)\n",
    "    train_set, dev_set, test_set = data[:5000], data[5000: 7000], data[7000:]\n",
    "\n",
    "    train_features, train_labels = split_feature_label(train_set)\n",
    "    dev_features, dev_labels = split_feature_label(dev_set)\n",
    "    test_features, test_labels = split_feature_label(test_set)\n",
    "\n",
    "    return train_features, train_labels, dev_features, \\\n",
    "        dev_labels, test_features, test_labels\n",
    "\n",
    "\n",
    "# preprocess (by z-normalization) the data for the regression task\n",
    "# return the normalized feature sets and corresponding target variables\n",
    "def prepare_load_regression_data():\n",
    "    train_features, train_labels, dev_features, \\\n",
    "        dev_labels, test_features, test_labels = load_data()\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler = scaler.fit(train_features)\n",
    "    train_features = pd.DataFrame(data=scaler.transform(train_features), columns=FEATURE_NAMES)\n",
    "    dev_features = pd.DataFrame(data=scaler.transform(dev_features), columns=FEATURE_NAMES)\n",
    "    test_features = pd.DataFrame(data=scaler.transform(test_features), columns=FEATURE_NAMES)\n",
    "\n",
    "    return train_features, train_labels, dev_features, \\\n",
    "        dev_labels, test_features, test_labels\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Training and Interpreting a Linear Regression Model\n",
    "\n",
    "**Q1**. (10)% Train a linear regression model (we recommend the statsmodels package) and report $R^2$ (goodness of fit) statistic.\n",
    "\n",
    "For model interpretability, provide for each feature (+ the bias variable) the following in tabular format:\n",
    "* Weight estimates\n",
    "* SE (standard error of estimates)\n",
    "* T statistics\n",
    "\n",
    "\n",
    "Further Questions regarding the linear model (answers to be included in the notebook):\n",
    "\n",
    "\n",
    "**Q2**. (5%) Which three features are the most important?\n",
    "\n",
    "**A2**: _Importance is signified by the T statistic. A negative weight tends to make PE (the target variable) decrease._\n",
    "_The three most important features: AT, V, RH_\n",
    "\n",
    "\n",
    "**Q3**. (10%) How does the gas turbine energy yield (EP) change with unit (one degree C) increase of the ambient temperature given that all other feature values remain the same? (Note: Here you should consider whether you use the original or z-normalized features to train your linear model.)\n",
    "\n",
    "**A3**: _Ambient temperature, AT, has a weight estimate of $-14.807970$. A one-degree change of AT would change the EP by $1\\degree \\mathrm{C}\\cdot \\mathrm{AT}= -14.807970$._\n",
    "\n",
    "**Q4**. (10%) Show bar graph illustrations of the feature effects for the first two validation set instances.\n",
    "\n",
    "**A4**: see plot below."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# We recommend the statsmodels package\n",
    "import statsmodels.api as sm\n",
    "# Hint, by default this sm does not include the bias/offset term w_0\n",
    "# thus, you should add it yourself using sm.add_constant()\n",
    "\n",
    "# Linear regression\n",
    "# Get the preprocessed data for linear regression modeling\n",
    "(train_features, train_labels, dev_features,\n",
    " dev_labels, test_features, test_labels) = prepare_load_regression_data()\n",
    "\n",
    "# 'const' column added with only 1s\n",
    "train_features_w0 = sm.add_constant(train_features)\n",
    "\n",
    "ols_model = sm.OLS(train_labels, train_features_w0)\n",
    "ols_result = ols_model.fit()\n",
    "\n",
    "model_data = pd.DataFrame({\n",
    "    'Weight estimates': ols_result.params,\n",
    "    'SE': ols_result.bse,\n",
    "    'T statistics': ols_result.tvalues,\n",
    "})\n",
    "\n",
    "# is rsquared a function or a property?\n",
    "# My linter says function, my interpreter says attribute/property.\n",
    "ols_r_squared = ols_result.rsquared\n",
    "\n",
    "most_important_features = model_data.sort_values(\"Weight estimates\")\n",
    "print(most_important_features)\n",
    "print(most_important_features[:3].index.tolist())\n",
    "print(\"r_squared: \", r_squared)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming the validation sets are the dev_features\n",
    "validation_features = dev_features\n",
    "#validation_features = test_features\n",
    "\n",
    "instances = dev_features[:2]\n",
    "instances_with_const = sm.add_constant(instances)\n",
    "predictions = ols_result.predict(instances_with_const)\n",
    "\n",
    "feature_multiplications = [\n",
    "    ols_result.params.values * instance\n",
    "    for instance in instances_with_const.values\n",
    "]\n",
    "\n",
    "for i in range(2):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(range(len(feature_multiplications[i])), feature_multiplications[i])\n",
    "    plt.title(f'Feature Effects on EP for Validation Instance {i + 1}')\n",
    "    plt.xticks(range(len(FEATURE_NAMES) + 1), ['const'] + FEATURE_NAMES, rotation=45)\n",
    "    plt.ylabel('Feature Effects')\n",
    "\n",
    "    plt.axhline(0, color='red', linewidth=0.4)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Q5**. (5%) Reflection: why would training a regression tree not work well for this dataset in terms of model interpretability? (answer in the notebook)\n",
    "\n",
    "**A5:** _The feature effect of the $w_0$ parameter is much greater than that of the other parameters and would result in the pruning getting rid of the influence of the other variables._"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Training and Interpreting an Explainable Boosting Model (Generalized Additive Model)\n",
    "**Q6**. (20% total) Train a Explainable Boosting Machine (with [interpret.ml](https://interpret.ml/docs/ebm.html))\n",
    "\n",
    "(Note on grading: Training EBM 5%, answering the questions - see below -  5% each)\n",
    "\n",
    "For a documentation see: [[LIME](https://interpret.ml/docs/lime.html)]\n",
    "\n",
    "* (5%) Visualize/provide global (model-wise) feature importances for EBM as a table or figure.\n",
    "* (5%) What are the most important two features in EBM? Are they the same as in the linear model?\n",
    "  * _AT and V have the greatest importance. And yes: In the linear model, it were AT, V, and RH. The EBM importance matches that of the linear model._\n",
    "* (5%) Visualize local (instance-wise) feature importances for a development set instance of your choice."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from interpret import set_visualize_provider\n",
    "from interpret.provider import InlineProvider\n",
    "set_visualize_provider(InlineProvider())\n",
    "from interpret.glassbox import ExplainableBoostingRegressor\n",
    "# add any other imports you need below\n",
    "\n",
    "from interpret import show\n",
    "\n",
    "# EBM\n",
    "ebm = ExplainableBoostingRegressor()\n",
    "ebm.fit(train_features, train_labels)  # takes 10-30 seconds"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"1.\")\n",
    "show(ebm.explain_global(\"Feature importances\"))\n",
    "print(\"-\"*30+\"\\n3.\")\n",
    "\n",
    "instance_id = 0\n",
    "show(ebm.explain_local(dev_features, dev_labels), instance_id)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Training and Explaining Neural Networks\n",
    "**Q7**. (15% total) Train a Neural Network (using the training and validation sets): One-layer MLP (ReLU activation function + 50 hidden neurons)\n",
    "\n",
    "We recommend to use the Adam optimizer. Fine-tune the learning rate and any other hyper-parameters you find necessary.\n",
    "\n",
    "For a tutorial see: [[Tutorial](https://scikit-learn.org/stable/modules/neural_networks_supervised.html)]\n",
    "\n",
    "Your code should report the results following the instructions below:\n",
    "\n",
    "Note on grading: training NN: 5%, answering below sub-questions 5% each.\n",
    "\n",
    "* (5%) Apply the trained neural network model on the test set and report Root Mean Square Error (RMSE) performance measure.\n",
    "\n",
    "* (5%) Analyzing factors influencing the neural network predictions.\n",
    "See the [Documentation](https://scikit-learn.org/stable/modules/partial_dependence.html) to use Partial Dependence Plot (PDP)  implementation in python. Use the trained one-layer MLP model to  Generate and report a bivariate PDP using 'AT' (Ambient Temperature) and 'V' (Exhaust Vacuum) features (Note: not two univariate PDPs but one bivariate PDP).\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "# One-layer MLP : you can use  learning_rate_init=0.001 with relu activation to get a reasonable model,\n",
    "# optimize other parameters by experimentation\n",
    "# We advise that you name variable for the mlp regressor model 'mlp_reg' so that it will be consistent\n",
    "# with the scripts to call your implementation of PFI later in Q8:\n",
    "\n",
    "mlp_reg = ...  # ... your scripts here and below\n",
    "\n",
    "\n",
    "mlp_reg = MLPRegressor(\n",
    "    solver=\"adam\",             # default\n",
    "    activation=\"relu\",         # default\n",
    "    hidden_layer_sizes=(50,),\n",
    "    max_iter=1000,\n",
    "    learning_rate_init=0.001,  # default\n",
    ")\n",
    "mlp_reg.fit(train_features, train_labels)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# RSME\n",
    "mlp_rsquared_test = root_mean_squared_error(dev_labels, mlp_reg.predict(dev_features))\n",
    "print(\"RMSE:\", mlp_rsquared_test)\n",
    "\n",
    "# PDP graph\n",
    "_ = PartialDependenceDisplay.from_estimator(mlp_reg, train_features, features=[\"AT\", \"V\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Generating Model-Agnostic Global Explanations for NN predictions\n",
    "\n",
    "**Permutation Feature Importance (PFI)**\n",
    "\n",
    "**Q8**. (25% total) PFI implementation and testing\n",
    "- (%15) Implement the permutation feature importance algorithm using RMSE as the error function. No existing libraries (save measuring RMSE) are allowed to use. We will implement it ourselves. Hint: to get a better error estimate per feature perturbation, you can run feature permutation multiple times (e.g., 10 times) and calculate the average.\n",
    "- (%5) Visualize feature importances obtained by PFI for the NN (one-layer MLP) model you trained using a bar graph.\n",
    "- (%5) Reflection: What are the most important two features obtained by PFI for MLP model? How do these two features compare to the top two features from the Linear Model and the EBM?"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Use the below function signature and the parameters to implement PFI\n",
    "\n",
    "def PFI(X: pd.DataFrame, labels: pd.DataFrame, model: MLPRegressor, orig_rmse: float) -> pd.DataFrame:\n",
    "# Your scripts implementing PFI here\n",
    "    # from https://scikit-learn.org/stable/modules/permutation_importance.html\n",
    "    #  section 5.2.1. Outline of the permutation importance algorithm\n",
    "\n",
    "    importances: dict[str, float] = {}\n",
    "    repetitions = 10\n",
    "\n",
    "    for feature in X.columns:\n",
    "        rmse_values: list[float] = []\n",
    "\n",
    "        for _ in range(repetitions):\n",
    "            X_corrupted = X.copy()  # noqa N806\n",
    "            X_corrupted[feature] = np.random.permutation(X_corrupted[feature])\n",
    "            prediction_corrupt = model.predict(X_corrupted)\n",
    "            corrupted_score = root_mean_squared_error(labels, prediction_corrupt)\n",
    "            rmse_values.append(corrupted_score)\n",
    "\n",
    "        # Use the previously calculated RMSE as reference score.\n",
    "        importance = orig_rmse - sum(rmse_values) / repetitions\n",
    "        importances[feature] = importance\n",
    "\n",
    "    # Convert to DataFrame for easier visualization\n",
    "    out = pd.DataFrame.from_dict(importances, orient='index', columns=['Importance'])\n",
    "    out.sort_values(by='Importance', ascending=False)#, inplace=True)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# Do not modify this part (unless you change the variable name mlp_reg above)\n",
    "base_rmse = root_mean_squared_error(dev_labels, mlp_reg.predict(dev_features))\n",
    "results_df = PFI(dev_features, dev_labels, mlp_reg, base_rmse)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Your scripts to visualize results_df using a bar graph here    plt.figure(figsize=(10, 6))\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.bar(results_df.index, results_df['Importance'], color='steelblue')\n",
    "plt.title('Permutation Feature Importance')\n",
    "plt.xlabel('Importance')\n",
    "plt.grid(axis='x',  alpha=0.4)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**A:** _The two most important features are AT and V. This is equivalent to the previous two models._"
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
